{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# pagaya-map_in_pandas\n",
    "\n",
    "Easy python wrapper for Spark mapInPandas, applyInPandas\n",
    "\n",
    "[this notebook on github](https://github.com/pagaya/conf-talks/blob/master/map_in_pandas/map_in_pandas.ipynb)\n",
    "\n",
    "## Goal\n",
    "Easily run legacy pandas-based python functions at scale on large amounts of data.\n",
    "\n",
    "## applications\n",
    "* Running legacy transformations, feature extraction etc.\n",
    "* large scale model-evaluation\n",
    "* large scale experiments and parameter tuning.\n",
    "* A-B testing\n",
    "* Concurrent training (e.g. xgboost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "DATA_PATH = \"/tmp/mappandas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo - map_in_pandas\n",
    "## load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------+---------+---------+---------+---------+---------+------+\n",
      "|amount|application.id|feature_a|feature_b|feature_c|feature_d|feature_e|  kind|\n",
      "+------+--------------+---------+---------+---------+---------+---------+------+\n",
      "| 49000|APP_0000002000|   0.5352|   0.5864|   0.2742|   0.2555|   0.3692|credit|\n",
      "| 34000|APP_0000002001|   0.9959|    0.861|   0.5087|   0.4358|   0.9352| unsec|\n",
      "| 16000|APP_0000002002|   0.3451|   0.0732|   0.4199|   0.0787|   0.8564| unsec|\n",
      "| 54000|APP_0000002003|   0.1399|    0.625|   0.1242|   0.0578|    0.435|   car|\n",
      "| 62000|APP_0000002004|   0.5025|   0.0957|   0.0221|   0.8953|   0.9904| unsec|\n",
      "| 50000|APP_0000002005|   0.3071|   0.9404|   0.9804|   0.3654|   0.7857| unsec|\n",
      "| 14000|APP_0000002006|   0.2114|   0.7633|   0.7932|   0.9443|   0.4359| unsec|\n",
      "| 42000|APP_0000002007|    0.952|   0.2578|   0.4235|   0.8583|   0.0501|credit|\n",
      "| 37000|APP_0000002008|   0.9496|   0.2498|   0.8821|   0.3216|   0.2862| unsec|\n",
      "| 15000|APP_0000002009|   0.0079|   0.9411|   0.5036|   0.1422|   0.7668| unsec|\n",
      "| 15000|APP_0000002010|   0.2401|   0.2707|   0.4621|   0.5937|   0.6482|credit|\n",
      "| 22000|APP_0000002011|   0.1467|    0.193|   0.2021|   0.6137|   0.3575|credit|\n",
      "| 59000|APP_0000002012|   0.3878|   0.1717|   0.1313|    0.625|   0.6895| unsec|\n",
      "| 38000|APP_0000002013|   0.6405|   0.3619|   0.2266|    0.676|   0.9447|   car|\n",
      "| 52000|APP_0000002014|    0.465|   0.8175|   0.4136|   0.5368|    0.213| unsec|\n",
      "| 44000|APP_0000002015|   0.3156|   0.4091|   0.8771|   0.3081|   0.1219| unsec|\n",
      "|  6000|APP_0000002016|   0.7758|    0.451|   0.7004|   0.8623|   0.3799| unsec|\n",
      "| 69000|APP_0000002017|   0.0406|   0.4942|   0.8426|   0.1353|   0.0537|   car|\n",
      "| 45000|APP_0000002018|   0.3852|   0.0034|   0.4666|   0.9666|   0.2939| unsec|\n",
      "| 46000|APP_0000002019|   0.2071|   0.4226|   0.8365|   0.2809|   0.0261|   car|\n",
      "+------+--------------+---------+---------+---------+---------+---------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "applications = spark.read.format(\"json\").load(DATA_PATH)  # see section 'create test data at the end'\n",
    "applications.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "# legacy code\n",
    "I have many legacy functions that work pandas->pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def legacy_preprocessing(pd_df):\n",
    "    pd_df['application.id'] = pd_df['application.id'] + \"/M\"\n",
    "    pd_df['ab'] = pd_df.feature_a + pd_df.feature_b\n",
    "    pd_df['cd'] = pd_df.feature_c * pd_df.feature_d\n",
    "    # remove the 'features_X' columns\n",
    "    return pd_df.drop(columns=[col for col in pd_df.columns if col.startswith(\"feature\")])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How I want things to work\n",
    "## (pagaya-map_in_pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 126:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------------+------+------------------+--------------------+\n",
      "|amount|  application.id|  kind|                ab|                  cd|\n",
      "+------+----------------+------+------------------+--------------------+\n",
      "| 49000|APP_0000002000/M|credit|            1.1216|           0.0700581|\n",
      "| 34000|APP_0000002001/M| unsec|            1.8569| 0.22169146000000003|\n",
      "| 16000|APP_0000002002/M| unsec|            0.4183|          0.03304613|\n",
      "| 54000|APP_0000002003/M|   car|            0.7649|          0.00717876|\n",
      "| 62000|APP_0000002004/M| unsec|            0.5982|0.019786130000000002|\n",
      "| 50000|APP_0000002005/M| unsec|            1.2475|          0.35823816|\n",
      "| 14000|APP_0000002006/M| unsec|            0.9747|          0.74901876|\n",
      "| 42000|APP_0000002007/M|credit|            1.2098| 0.36349004999999995|\n",
      "| 37000|APP_0000002008/M| unsec|            1.1994|          0.28368336|\n",
      "| 15000|APP_0000002009/M| unsec|0.9490000000000001| 0.07161192000000001|\n",
      "| 15000|APP_0000002010/M|credit|            0.5108|          0.27434877|\n",
      "| 22000|APP_0000002011/M|credit|            0.3397| 0.12402877000000001|\n",
      "| 59000|APP_0000002012/M| unsec|            0.5595|           0.0820625|\n",
      "| 38000|APP_0000002013/M|   car|            1.0024|           0.1531816|\n",
      "| 52000|APP_0000002014/M| unsec|            1.2825| 0.22202048000000005|\n",
      "| 44000|APP_0000002015/M| unsec|            0.7247|          0.27023451|\n",
      "|  6000|APP_0000002016/M| unsec|1.2268000000000001|          0.60395492|\n",
      "| 69000|APP_0000002017/M|   car|0.5347999999999999|          0.11400378|\n",
      "| 45000|APP_0000002018/M| unsec|            0.3886| 0.45101556000000004|\n",
      "| 46000|APP_0000002019/M|   car|0.6296999999999999| 0.23497284999999998|\n",
      "+------+----------------+------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from map_in_pandas import mappandas\n",
    "results = mappandas.map_in_pandas(spark, applications, legacy_preprocessing)\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The reality of working with spark.mapInPandas\n",
    "## schema\n",
    "Spark mapInPandas expects me to define a schema. \n",
    "\n",
    "However - I did not write the function - I don't know which fields it returns.\n",
    "\n",
    "I need to run the function on a small chunk of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>amount</th>\n",
       "      <th>application.id</th>\n",
       "      <th>kind</th>\n",
       "      <th>ab</th>\n",
       "      <th>cd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49000</td>\n",
       "      <td>APP_0000002000/M</td>\n",
       "      <td>credit</td>\n",
       "      <td>1.1216</td>\n",
       "      <td>0.070058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34000</td>\n",
       "      <td>APP_0000002001/M</td>\n",
       "      <td>unsec</td>\n",
       "      <td>1.8569</td>\n",
       "      <td>0.221691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16000</td>\n",
       "      <td>APP_0000002002/M</td>\n",
       "      <td>unsec</td>\n",
       "      <td>0.4183</td>\n",
       "      <td>0.033046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54000</td>\n",
       "      <td>APP_0000002003/M</td>\n",
       "      <td>car</td>\n",
       "      <td>0.7649</td>\n",
       "      <td>0.007179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62000</td>\n",
       "      <td>APP_0000002004/M</td>\n",
       "      <td>unsec</td>\n",
       "      <td>0.5982</td>\n",
       "      <td>0.019786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>19000</td>\n",
       "      <td>APP_0000002095/M</td>\n",
       "      <td>unsec</td>\n",
       "      <td>1.3200</td>\n",
       "      <td>0.184994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>8000</td>\n",
       "      <td>APP_0000002096/M</td>\n",
       "      <td>credit</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>0.074676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>24000</td>\n",
       "      <td>APP_0000002097/M</td>\n",
       "      <td>car</td>\n",
       "      <td>1.8845</td>\n",
       "      <td>0.284798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>19000</td>\n",
       "      <td>APP_0000002098/M</td>\n",
       "      <td>unsec</td>\n",
       "      <td>1.4615</td>\n",
       "      <td>0.168691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>72000</td>\n",
       "      <td>APP_0000002099/M</td>\n",
       "      <td>unsec</td>\n",
       "      <td>1.0677</td>\n",
       "      <td>0.973511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    amount    application.id    kind      ab        cd\n",
       "0    49000  APP_0000002000/M  credit  1.1216  0.070058\n",
       "1    34000  APP_0000002001/M   unsec  1.8569  0.221691\n",
       "2    16000  APP_0000002002/M   unsec  0.4183  0.033046\n",
       "3    54000  APP_0000002003/M     car  0.7649  0.007179\n",
       "4    62000  APP_0000002004/M   unsec  0.5982  0.019786\n",
       "..     ...               ...     ...     ...       ...\n",
       "95   19000  APP_0000002095/M   unsec  1.3200  0.184994\n",
       "96    8000  APP_0000002096/M  credit  0.7184  0.074676\n",
       "97   24000  APP_0000002097/M     car  1.8845  0.284798\n",
       "98   19000  APP_0000002098/M   unsec  1.4615  0.168691\n",
       "99   72000  APP_0000002099/M   unsec  1.0677  0.973511\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_results = legacy_preprocessing(applications.limit(100).toPandas())\n",
    "small_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I can now know the schems:\n",
    "# schema must have `` around field names with special characters\n",
    "RESULT_SCHEMA = \"`application.id` string, kind string, amount int, ab float, cd float\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark API akwardness\n",
    "\n",
    "mapInPandas accepts a function that get several pd.Dataframes (an iterator) \n",
    "and returns several pd.Dataframe\n",
    "\n",
    "So I need to wrap the legacy function in a for-loop generator\n",
    "\n",
    "## other weird bugs\n",
    "There are some bugs with fields that have '.' in them - even if surrounded by `"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Cannot resolve column name \"application.id\" among (amount, application.id, feature_a, feature_b, feature_c, feature_d, feature_e, kind); did you mean to quote the `application.id` column?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [91]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m pd_df \u001b[38;5;129;01min\u001b[39;00m pd_df_iter:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m legacy_preprocessing(pd_df)\n\u001b[0;32m----> 5\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmapInPandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlegacy_preprocessing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mRESULT_SCHEMA\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/pandas/map_ops.py:81\u001b[0m, in \u001b[0;36mPandasMapOpsMixin.mapInPandas\u001b[0;34m(self, func, schema)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, DataFrame)\n\u001b[1;32m     79\u001b[0m udf \u001b[38;5;241m=\u001b[39m pandas_udf(\n\u001b[1;32m     80\u001b[0m     func, returnType\u001b[38;5;241m=\u001b[39mschema, functionType\u001b[38;5;241m=\u001b[39mPythonEvalType\u001b[38;5;241m.\u001b[39mSQL_MAP_PANDAS_ITER_UDF)\n\u001b[0;32m---> 81\u001b[0m udf_column \u001b[38;5;241m=\u001b[39m udf(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28mself\u001b[39m[col] \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m     82\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mmapInPandas(udf_column\u001b[38;5;241m.\u001b[39m_jc\u001b[38;5;241m.\u001b[39mexpr())\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/pandas/map_ops.py:81\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, DataFrame)\n\u001b[1;32m     79\u001b[0m udf \u001b[38;5;241m=\u001b[39m pandas_udf(\n\u001b[1;32m     80\u001b[0m     func, returnType\u001b[38;5;241m=\u001b[39mschema, functionType\u001b[38;5;241m=\u001b[39mPythonEvalType\u001b[38;5;241m.\u001b[39mSQL_MAP_PANDAS_ITER_UDF)\n\u001b[0;32m---> 81\u001b[0m udf_column \u001b[38;5;241m=\u001b[39m udf(\u001b[38;5;241m*\u001b[39m[\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns])\n\u001b[1;32m     82\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mmapInPandas(udf_column\u001b[38;5;241m.\u001b[39m_jc\u001b[38;5;241m.\u001b[39mexpr())\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/dataframe.py:1636\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   1620\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the column as a :class:`Column`.\u001b[39;00m\n\u001b[1;32m   1621\u001b[0m \n\u001b[1;32m   1622\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1633\u001b[0m \u001b[38;5;124;03m[Row(age=5, name='Bob')]\u001b[39;00m\n\u001b[1;32m   1634\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m-> 1636\u001b[0m     jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1637\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n\u001b[1;32m   1638\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, Column):\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/python/lib/py4j-0.10.9.2-src.zip/py4j/java_gateway.py:1309\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1303\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1305\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1306\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1308\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1309\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1313\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m~/pyenv/ds/lib/python3.8/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Cannot resolve column name \"application.id\" among (amount, application.id, feature_a, feature_b, feature_c, feature_d, feature_e, kind); did you mean to quote the `application.id` column?"
     ]
    }
   ],
   "source": [
    "def legacy_wrapper(pd_df_iter):\n",
    "    # mapInPandas accepts a function that get several pd.Dataframes (an iterator) and returns several pd.Dataframe\n",
    "    for pd_df in pd_df_iter:\n",
    "        yield legacy_preprocessing(pd_df)\n",
    "results = applications.mapInPandas(legacy_preprocessing, RESULT_SCHEMA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's work-around the bugs \n",
    "Fix the data so there is no special character in column names\n",
    "## fix the legacy function\n",
    "This is the worse - I need to get into a function I don't know and try to fix its name handling\n",
    "\n",
    "## And... we made it\n",
    "We manged to scale the code.\n",
    "\n",
    "For one function..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 129:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+------+------+----------+\n",
      "|  application_id|  kind|amount|    ab|        cd|\n",
      "+----------------+------+------+------+----------+\n",
      "|APP_0000002000/M|credit| 49000|1.1216| 0.0700581|\n",
      "|APP_0000002001/M| unsec| 34000|1.8569|0.22169146|\n",
      "|APP_0000002002/M| unsec| 16000|0.4183|0.03304613|\n",
      "|APP_0000002003/M|   car| 54000|0.7649|0.00717876|\n",
      "|APP_0000002004/M| unsec| 62000|0.5982|0.01978613|\n",
      "|APP_0000002005/M| unsec| 50000|1.2475|0.35823816|\n",
      "|APP_0000002006/M| unsec| 14000|0.9747| 0.7490188|\n",
      "|APP_0000002007/M|credit| 42000|1.2098|0.36349005|\n",
      "|APP_0000002008/M| unsec| 37000|1.1994|0.28368336|\n",
      "|APP_0000002009/M| unsec| 15000| 0.949|0.07161192|\n",
      "|APP_0000002010/M|credit| 15000|0.5108|0.27434877|\n",
      "|APP_0000002011/M|credit| 22000|0.3397|0.12402877|\n",
      "|APP_0000002012/M| unsec| 59000|0.5595| 0.0820625|\n",
      "|APP_0000002013/M|   car| 38000|1.0024| 0.1531816|\n",
      "|APP_0000002014/M| unsec| 52000|1.2825|0.22202048|\n",
      "|APP_0000002015/M| unsec| 44000|0.7247| 0.2702345|\n",
      "|APP_0000002016/M| unsec|  6000|1.2268| 0.6039549|\n",
      "|APP_0000002017/M|   car| 69000|0.5348|0.11400378|\n",
      "|APP_0000002018/M| unsec| 45000|0.3886|0.45101556|\n",
      "|APP_0000002019/M|   car| 46000|0.6297|0.23497285|\n",
      "+----------------+------+------+------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "applications_FIXED = applications.withColumnRenamed('application.id', 'application_id')  ### Fix the data\n",
    "\n",
    "def legacy_preprocessing_FIXED(pd_df):\n",
    "    pd_df['application_id'] = pd_df['application_id'] + \"/M\"  ### had to fix this line\n",
    "    pd_df['ab'] = pd_df.feature_a + pd_df.feature_b\n",
    "    pd_df['cd'] = pd_df.feature_c * pd_df.feature_d\n",
    "    # remove the 'features_X' columns\n",
    "    return pd_df.drop(columns=[col for col in pd_df.columns if col.startswith(\"feature\")])\n",
    "\n",
    "\n",
    "RESULT_SCHEMA_FIXED = \"application_id string, kind string, amount int, ab float, cd float\"\n",
    "\n",
    "def legacy_wrapper_FIXED(pd_df_iter):\n",
    "    for pd_df in pd_df_iter:\n",
    "        yield legacy_preprocessing_FIXED(pd_df)\n",
    "\n",
    "results = applications_FIXED.mapInPandas(legacy_wrapper_FIXED, RESULT_SCHEMA_FIXED)\n",
    "results.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# working with spark.applyInPandas\n",
    "\n",
    "All the above issues and bugs in Spark also occure in applyInPandas.\n",
    "Our map_in_pandas API also wraps mapInPandas by allowing to pass a\n",
    "\n",
    "`group_by=[col1, col2]` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 135:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|  kind|count|\n",
      "+------+-----+\n",
      "|   car| 3335|\n",
      "|credit| 3274|\n",
      "| unsec| 3391|\n",
      "+------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from map_in_pandas import mappandas\n",
    "def legacy_grouping(pd_df):\n",
    "    return pd.DataFrame({\"kind\": [pd_df[\"kind\"].iloc[0]], \"count\": [len(pd_df)]})\n",
    "\n",
    "results = mappandas.map_in_pandas(spark, applications, legacy_grouping, group_by=['kind'])\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging the Python function\n",
    "In Spark the function passed to map_in_pandas (e.g. `legacy_preprocessing`) is run distributly on the executors. Debugging on the executors is hard. To see print/logs or exception - you need to collect logs after the run. Yuo cannot put break points.\n",
    "\n",
    "## `debug_local_row_count=`\n",
    "To Allow running the function locally on the driver - you can temporarily add the parameter `debug_local_row_count=1000` to run the function on a local sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG - too large ab features\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def legacy_preprocessing(pd_df):\n",
    "    pd_df['application.id'] = pd_df['application.id'] + \"/M\"\n",
    "    pd_df['ab'] = pd_df.feature_a + pd_df.feature_b\n",
    "    pd_df['cd'] = pd_df.feature_c * pd_df.feature_d\n",
    "    if pd_df['ab'].sum() > 0.8 * len(pd_df):\n",
    "        print(\"DEBUG - too large ab features\")\n",
    "    # remove the 'features_X' columns\n",
    "    return pd_df.drop(columns=[col for col in pd_df.columns if col.startswith(\"feature\")])\n",
    "\n",
    "results = mappandas.map_in_pandas(spark, applications, legacy_preprocessing, debug_local_row_count=1000)\n",
    "results.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (Creating test data)\n",
    "(Run only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_MONTHS = 36\n",
    "N_APPLICAIONS = 10_000\n",
    "applications1 = spark.range(N_APPLICAIONS, numPartitions=10).selectExpr(\n",
    "    \"printf('APP_%010d', INT(id)) AS `application.id`\",\n",
    "    \"INT(rand() * 100) * 1000 as amount\", \n",
    "    \"array('car', 'unsec', 'credit')[int(rand()*3)] as kind\",\n",
    "    *[f\"round(rand(), 4) AS feature_{x}\" for x in \"abcde\"])\n",
    "applications1.write.mode(\"overwrite\").format(\"json\").save(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 3200\n",
      "-rw-r--r--  1 tal.franji  wheel       0 Jun 19 11:05 _SUCCESS\n",
      "-rw-r--r--  1 tal.franji  wheel  159907 Jun 19 11:05 part-00000-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159896 Jun 19 11:05 part-00001-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  160036 Jun 19 11:05 part-00002-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159975 Jun 19 11:05 part-00003-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159939 Jun 19 11:05 part-00004-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  160002 Jun 19 11:05 part-00005-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159976 Jun 19 11:05 part-00006-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159949 Jun 19 11:05 part-00007-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159952 Jun 19 11:05 part-00008-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "-rw-r--r--  1 tal.franji  wheel  159969 Jun 19 11:05 part-00009-0b485855-3f44-4d3a-8228-beae45877f32-c000.json\n",
      "{\"application.id\":\"APP_0000009000\",\"amount\":14000,\"kind\":\"car\",\"feature_a\":0.9913,\"feature_b\":0.9598,\"feature_c\":0.0416,\"feature_d\":0.1816,\"feature_e\":0.9528}\n",
      "{\"application.id\":\"APP_0000009001\",\"amount\":35000,\"kind\":\"car\",\"feature_a\":0.0407,\"feature_b\":0.3433,\"feature_c\":0.5843,\"feature_d\":0.0148,\"feature_e\":0.2293}\n",
      "{\"application.id\":\"APP_0000009002\",\"amount\":73000,\"kind\":\"credit\",\"feature_a\":0.4312,\"feature_b\":0.0274,\"feature_c\":0.203,\"feature_d\":0.3713,\"feature_e\":0.4484}\n",
      "{\"application.id\":\"APP_0000009003\",\"amount\":13000,\"kind\":\"unsec\",\"feature_a\":0.2303,\"feature_b\":0.681,\"feature_c\":0.0609,\"feature_d\":0.4789,\"feature_e\":0.533}\n",
      "{\"application.id\":\"APP_0000009004\",\"amount\":53000,\"kind\":\"credit\",\"feature_a\":0.3169,\"feature_b\":0.6526,\"feature_c\":0.0846,\"feature_d\":0.6855,\"feature_e\":0.8798}\n",
      "{\"application.id\":\"APP_0000009005\",\"amount\":46000,\"kind\":\"credit\",\"feature_a\":0.1616,\"feature_b\":0.0719,\"feature_c\":0.2931,\"feature_d\":0.5761,\"feature_e\":0.0063}\n",
      "{\"application.id\":\"APP_0000009006\",\"amount\":91000,\"kind\":\"car\",\"feature_a\":0.1491,\"feature_b\":0.9554,\"feature_c\":0.674,\"feature_d\":0.2911,\"feature_e\":0.111}\n",
      "{\"application.id\":\"APP_0000009007\",\"amount\":32000,\"kind\":\"unsec\",\"feature_a\":0.1359,\"feature_b\":0.5532,\"feature_c\":0.6663,\"feature_d\":0.1798,\"feature_e\":0.6317}\n",
      "{\"application.id\":\"APP_0000009008\",\"amount\":89000,\"kind\":\"unsec\",\"feature_a\":0.5125,\"feature_b\":0.2449,\"feature_c\":0.4809,\"feature_d\":0.1906,\"feature_e\":0.513}\n",
      "{\"application.id\":\"APP_0000009009\",\"amount\":47000,\"kind\":\"car\",\"feature_a\":0.0896,\"feature_b\":0.7903,\"feature_c\":0.6483,\"feature_d\":0.166,\"feature_e\":0.995}\n"
     ]
    }
   ],
   "source": [
    "!ls -l {DATA_PATH}\n",
    "!head {DATA_PATH}{os.listdir(DATA_PATH)[1]}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
